{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"We are about to study the idea of a computational process. Computational processes are abstract beings that inhabit computers. As they evolve, processes manipulate other abstract things called data. The evolution of a process is directed by a pattern of rules called a program. People create programs to direct processes. In effect, we conjure the spirits of the computer with our spells.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace(',', '').replace('.','')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(set(clean_text(raw_text).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['manipulate', 'The', 'effect', 'spells', 'Computational', 'computers', 'our', 'As', 'to', 'that', 'a', 'evolve', 'idea', 'with', 'We', 'rules', 'the', 'spirits', 'are', 'about', 'direct', 'program', 'programs', 'data', 'by', 'computational', 'inhabit', 'pattern', 'processes', 'In', 'abstract', 'called', 'conjure', 'create', 'computer', 'study', 'of', 'other', 'beings', 'evolution', 'is', 'directed', 'we', 'process', 'they', 'things', 'People']\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = dict()\n",
    "word2id = dict()\n",
    "for i, word in enumerate(text):\n",
    "    id2word[i] = word\n",
    "    word2id[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skipgram(sentence, window_size=2, neg_samples=5, raw_sentence=False):\n",
    "    pairs = []\n",
    "    if raw_sentence:\n",
    "        sentence = sentence.lower().split()\n",
    "    \n",
    "    for i, word in enumerate(sentence):\n",
    "        cnt = 0\n",
    "        for j in range(-window_size, window_size+1):\n",
    "            if j != 0 and (i+j) >= 0 and (i+j) < len(sentence):\n",
    "                pairs.append((sentence[i], sentence[i+j], 1))\n",
    "                cnt += 1\n",
    "                \n",
    "        #NAIVE negative sampling\n",
    "        for _ in range(neg_samples):\n",
    "            ran_num = random.randint(0, len(word2id)-1)\n",
    "            while ran_num == word2id[word]:\n",
    "                ran_num = random.randint(0, len(word2id)-1)\n",
    "            neg_sample = id2word[ran_num]\n",
    "            pairs.append((sentence[i], neg_sample, 0))\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_to_input(pairs, id2word, word2id):\n",
    "    center_ix = []\n",
    "    context_ix = []\n",
    "    targets = []\n",
    "    for pair in pairs:\n",
    "        center_ix.append(word2id[pair[0]])\n",
    "        context_ix.append(word2id[pair[1]])\n",
    "        targets.append(pair[2])\n",
    "    \n",
    "    return center_ix, context_ix, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = skipgram(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_ix, context_ix, targets = pair_to_input(pairs, id2word, word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Skipgram(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super(Skipgram, self).__init__()\n",
    "        self.center_emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.context_emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "    def forward(self, u_ix, v_ix):\n",
    "        \n",
    "        u = self.context_emb(u_ix).view(1,-1)\n",
    "        v = self.center_emb(v_ix).view(1,-1)\n",
    "        score = torch.mm(u, v.transpose(1,0))\n",
    "        \n",
    "        return torch.sigmoid(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skipgram(\n",
       "  (center_emb): Embedding(47, 100)\n",
       "  (context_emb): Embedding(47, 100)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Skipgram(len(word2id), 100)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    optimizer = optim.SGD(lr=1e-3, params=model.parameters())\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        for i in range(len(pairs)):\n",
    "            center = torch.tensor(center_ix[i]).to(device).long()\n",
    "            context = torch.tensor(context_ix[i]).to(device).long()\n",
    "            target = torch.tensor(targets[i]).view(1,-1).to(device).float()\n",
    "            \n",
    "            out = model.forward(context, center)\n",
    "            loss = F.binary_cross_entropy(out, target)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i+1) % 300 == 0:\n",
    "                print('Epoch %d  %d steps, loss : %0.4f' %(epoch+1, i+1, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  300 steps, loss : 0.0984\n",
      "Epoch 2  300 steps, loss : 0.0968\n",
      "Epoch 3  300 steps, loss : 0.0952\n",
      "Epoch 4  300 steps, loss : 0.0937\n",
      "Epoch 5  300 steps, loss : 0.0923\n",
      "Epoch 6  300 steps, loss : 0.0908\n",
      "Epoch 7  300 steps, loss : 0.0895\n",
      "Epoch 8  300 steps, loss : 0.0881\n",
      "Epoch 9  300 steps, loss : 0.0868\n",
      "Epoch 10  300 steps, loss : 0.0856\n",
      "Epoch 11  300 steps, loss : 0.0843\n",
      "Epoch 12  300 steps, loss : 0.0832\n",
      "Epoch 13  300 steps, loss : 0.0820\n",
      "Epoch 14  300 steps, loss : 0.0809\n",
      "Epoch 15  300 steps, loss : 0.0798\n",
      "Epoch 16  300 steps, loss : 0.0787\n",
      "Epoch 17  300 steps, loss : 0.0777\n",
      "Epoch 18  300 steps, loss : 0.0767\n",
      "Epoch 19  300 steps, loss : 0.0757\n",
      "Epoch 20  300 steps, loss : 0.0747\n",
      "Epoch 21  300 steps, loss : 0.0738\n",
      "Epoch 22  300 steps, loss : 0.0729\n",
      "Epoch 23  300 steps, loss : 0.0720\n",
      "Epoch 24  300 steps, loss : 0.0711\n",
      "Epoch 25  300 steps, loss : 0.0703\n",
      "Epoch 26  300 steps, loss : 0.0695\n",
      "Epoch 27  300 steps, loss : 0.0686\n",
      "Epoch 28  300 steps, loss : 0.0679\n",
      "Epoch 29  300 steps, loss : 0.0671\n",
      "Epoch 30  300 steps, loss : 0.0663\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_neighbors(word, model, k=3):\n",
    "    \n",
    "    embedding = model.center_emb.weight #(vocab_size x dim)\n",
    "    word_emb = embedding[word2id[word]] #(1 x dim)\n",
    "    \n",
    "    distances = []\n",
    "    for word in embedding:\n",
    "        distances.append(torch.pow(torch.pow(word - word_emb, 2).sum(), 0.5))\n",
    "    similarities = torch.mm(embedding, word_emb.view(1,-1).transpose(1,0)).cpu().detach().numpy()\n",
    "    \n",
    "    _, closest = torch.topk(torch.tensor(distances), k+1, largest=False)\n",
    "    closest = closest.cpu().detach().numpy().tolist()\n",
    "    \n",
    "    words = []\n",
    "    for i, close in enumerate(closest):\n",
    "        if i != 0:\n",
    "            words.append(id2word[close])\n",
    "    print('%d closest words :' %k, words)\n",
    "    \n",
    "    #return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 closest words : ['they', 'that', 'evolve', 'rules', 'to']\n"
     ]
    }
   ],
   "source": [
    "n_neighbors('inhabit', model, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
